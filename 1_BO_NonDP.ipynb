{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871ffe8b",
   "metadata": {},
   "source": [
    "## Initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3d15409",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "dataset = 'adult'\n",
    "mechanism = \"non_private\"\n",
    "folder_name = 'results/' + dataset + '/' + mechanism\n",
    "\n",
    "# for ML\n",
    "if dataset == 'adult':\n",
    "    target = 'income'\n",
    "    protected_attribute = 'gender'\n",
    "    \n",
    "elif dataset == 'ACSCoverage':\n",
    "    target = 'PUBCOV'\n",
    "    protected_attribute = 'DIS'\n",
    "    \n",
    "elif dataset == 'LSAC':\n",
    "    target = 'pass_bar'\n",
    "    protected_attribute = 'race1' \n",
    "    \n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895b9d1",
   "metadata": {},
   "source": [
    "## Write function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662cbe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(folder_name, values):\n",
    "    with open(folder_name + \"/LGBM_BO_results.csv\", mode='a', newline='') as scores_file:\n",
    "        scores_writer = csv.writer(scores_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        scores_writer.writerow(values)\n",
    "    scores_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d68cb2",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ede42761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import csv\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score, recall_score\n",
    "\n",
    "# hyper-params opti\n",
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "# designed functions\n",
    "from functions import fairness_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d356a",
   "metadata": {},
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b48384",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>native-country</th>\n",
       "      <th>relationship</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45844</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45845</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45846</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45847</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45848</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45849 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  education  marital-status  occupation  native-country  \\\n",
       "0       23          2          9               2          12              38   \n",
       "1        4          2         15               0           2              38   \n",
       "2        0          2          1               4           7              38   \n",
       "3       34          2         11               2          11               0   \n",
       "4        9          2          9               4           3              38   \n",
       "...    ...        ...        ...             ...         ...             ...   \n",
       "45844   18          2          9               2           4              40   \n",
       "45845   20          4          9               2          11              39   \n",
       "45846    7          2          8               4          11              38   \n",
       "45847    7          2         15               4           0              38   \n",
       "45848   22          5         11               2           0              38   \n",
       "\n",
       "       relationship  hours-per-week  gender  race  income  \n",
       "0                 5              19       0     4       1  \n",
       "1                 3              39       1     4       0  \n",
       "2                 3               9       1     4       0  \n",
       "3                 0              49       1     1       1  \n",
       "4                 1              37       1     4       1  \n",
       "...             ...             ...     ...   ...     ...  \n",
       "45844             0              64       1     4       1  \n",
       "45845             0              75       1     1       1  \n",
       "45846             1              54       1     4       0  \n",
       "45847             1              39       0     4       0  \n",
       "45848             5              19       0     1       1  \n",
       "\n",
       "[45849 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if dataset == 'adult':\n",
    "    df = pd.read_csv('datasets/db_adult_processed_26k.csv')\n",
    "    \n",
    "elif dataset == 'ACSCoverage':\n",
    "    df = pd.read_csv('datasets/db_ACSCoverage.csv')\n",
    "\n",
    "elif dataset == 'LSAC':\n",
    "    df = pd.read_csv('datasets/db_LSAC.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b02848",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee6aefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_0</th>\n",
       "      <th>age_1</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>age_5</th>\n",
       "      <th>age_6</th>\n",
       "      <th>age_7</th>\n",
       "      <th>age_8</th>\n",
       "      <th>age_9</th>\n",
       "      <th>...</th>\n",
       "      <th>hours-per-week_94</th>\n",
       "      <th>hours-per-week_95</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>race_0</th>\n",
       "      <th>race_1</th>\n",
       "      <th>race_2</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45844</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45845</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45846</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45847</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45848</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45849 rows Ã— 269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_0  age_1  age_2  age_3  age_4  age_5  age_6  age_7  age_8  age_9  \\\n",
       "0        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1        0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2        1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "45844    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "45845    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "45846    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "45847    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "45848    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       ...  hours-per-week_94  hours-per-week_95  gender_0  gender_1  race_0  \\\n",
       "0      ...                0.0                0.0       1.0       0.0     0.0   \n",
       "1      ...                0.0                0.0       0.0       1.0     0.0   \n",
       "2      ...                0.0                0.0       0.0       1.0     0.0   \n",
       "3      ...                0.0                0.0       0.0       1.0     0.0   \n",
       "4      ...                0.0                0.0       0.0       1.0     0.0   \n",
       "...    ...                ...                ...       ...       ...     ...   \n",
       "45844  ...                0.0                0.0       0.0       1.0     0.0   \n",
       "45845  ...                0.0                0.0       0.0       1.0     0.0   \n",
       "45846  ...                0.0                0.0       0.0       1.0     0.0   \n",
       "45847  ...                0.0                0.0       1.0       0.0     0.0   \n",
       "45848  ...                0.0                0.0       1.0       0.0     0.0   \n",
       "\n",
       "       race_1  race_2  race_3  race_4  income  \n",
       "0         0.0     0.0     0.0     1.0       1  \n",
       "1         0.0     0.0     0.0     1.0       0  \n",
       "2         0.0     0.0     0.0     1.0       0  \n",
       "3         1.0     0.0     0.0     0.0       1  \n",
       "4         0.0     0.0     0.0     1.0       1  \n",
       "...       ...     ...     ...     ...     ...  \n",
       "45844     0.0     0.0     0.0     1.0       1  \n",
       "45845     1.0     0.0     0.0     0.0       1  \n",
       "45846     0.0     0.0     0.0     1.0       0  \n",
       "45847     0.0     0.0     0.0     1.0       0  \n",
       "45848     1.0     0.0     0.0     0.0       1  \n",
       "\n",
       "[45849 rows x 269 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_df = []\n",
    "for col in df.columns:\n",
    "    \n",
    "    if col != target:\n",
    "        lst_col_name = [col+\"_{}\".format(val) for val in range(len(set(df[col])))]\n",
    "\n",
    "        k = len(set(df[col]))\n",
    "\n",
    "        OHE = np.eye(k)\n",
    "\n",
    "        df_ohe = pd.DataFrame([OHE[val] for val in df[col]], columns=lst_col_name)\n",
    "        lst_df.append(df_ohe)\n",
    "df = pd.concat([pd.concat(lst_df, axis=1), df[target]], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ddd11",
   "metadata": {},
   "source": [
    "## Splitting train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e670d45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36679, 268), (36679,), (9170, 268), (9170,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = copy.deepcopy(df.drop(target, axis=1))\n",
    "y = copy.deepcopy(df[target])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True, stratify=y, random_state=seed)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ca45d",
   "metadata": {},
   "source": [
    "## Single Run of Non-private LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf5ce9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics\n",
      "acc: 0.8182115594329334\n",
      "f1: 0.8281974647016387\n",
      "auc: 0.8171779914854769\n",
      "recall: 0.8462510530749789\n",
      "\n",
      "Fairness Metrics\n",
      "SP_a_1: 0.6675868788567717\n",
      "SP_a_0: 0.28021248339973437\n",
      "DI: 0.4197393511981426\n",
      "SPD: 0.38737439545703733\n",
      "EO_a_1: 0.896945551128818\n",
      "EO_a_0: 0.6520854526958291\n",
      "EOD: 0.24486009843298895\n",
      "OA_a_1: 0.8177979863592075\n",
      "OA_a_0: 0.8190571049136787\n",
      "OAD: -0.0012591185544711392\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(random_state=seed, n_jobs=-1, objective=\"binary\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# performance metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print('Performance Metrics')\n",
    "print(\"acc:\", acc)\n",
    "print(\"f1:\", f1)\n",
    "print(\"auc:\", auc)\n",
    "print(\"recall:\", recall)\n",
    "\n",
    "# prepare dataset for fairness metrics\n",
    "df_fm = pd.concat([X_test, y_test], axis=1)\n",
    "df_fm['y_pred'] = y_pred\n",
    "\n",
    "print('\\nFairness Metrics')\n",
    "\n",
    "fair_met = fairness_metrics(df_fm, protected_attribute, target)\n",
    "\n",
    "for key in fair_met.keys():\n",
    "    print(key+\":\", fair_met[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355d0a9a",
   "metadata": {},
   "source": [
    "## Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59b6feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(space):\n",
    "    \n",
    "    global seed, ITER, X_train, y_train, X_test, y_test\n",
    "    \n",
    "    ITER += 1\n",
    "    \n",
    "    params = {'max_depth': int(space['max_depth']), \n",
    "              'learning_rate': space['learning_rate'],\n",
    "              'n_estimators': int(space['n_estimators']),\n",
    "             }\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    print(ITER, \":: \", params)\n",
    "    \n",
    "    # Initialize and fit model\n",
    "    model = LGBMClassifier(random_state=seed, n_jobs=-1, objective=\"binary\")\n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Performance metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "        \n",
    "    # write [\"iter\", \"acc\", \"f1-score\", \"auc\", \"recall\", \"cm\", \"params\"]\n",
    "    write(folder_name, [str(ITER),\n",
    "           acc,\n",
    "           f1,\n",
    "           auc,\n",
    "           recall,\n",
    "           cm,\n",
    "           params])\n",
    "\n",
    "    print(\"loss:\", auc)\n",
    "    \n",
    "    # maximize AUC metric\n",
    "    return {'loss':-auc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3321d2",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "366cd73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "1 ::  {'max_depth': 31, 'learning_rate': 0.2221423901134277, 'n_estimators': 1650}\n",
      "loss: 0.7937075650315475\n",
      "----------------------------------------------------------------------------\n",
      "2 ::  {'max_depth': 30, 'learning_rate': 0.21662331565922432, 'n_estimators': 650}\n",
      "loss: 0.8070529446662682\n",
      "----------------------------------------------------------------------------\n",
      "3 ::  {'max_depth': 3, 'learning_rate': 0.15823860430552075, 'n_estimators': 350}\n",
      "loss: 0.8137571886298764\n",
      "----------------------------------------------------------------------------\n",
      "4 ::  {'max_depth': 10, 'learning_rate': 0.1521888191981938, 'n_estimators': 850}\n",
      "loss: 0.8094628717483274\n",
      "----------------------------------------------------------------------------\n",
      "5 ::  {'max_depth': 4, 'learning_rate': 0.07896551676477612, 'n_estimators': 1050}\n",
      "loss: 0.8137727156512757\n",
      "----------------------------------------------------------------------------\n",
      "6 ::  {'max_depth': 7, 'learning_rate': 0.11606641560458879, 'n_estimators': 1500}\n",
      "loss: 0.8053447341678679\n",
      "----------------------------------------------------------------------------\n",
      "7 ::  {'max_depth': 50, 'learning_rate': 0.0296192660685174, 'n_estimators': 1400}\n",
      "loss: 0.8131098166211144\n",
      "----------------------------------------------------------------------------\n",
      "8 ::  {'max_depth': 41, 'learning_rate': 0.1895285855104962, 'n_estimators': 200}\n",
      "loss: 0.8142715807498464\n",
      "----------------------------------------------------------------------------\n",
      "9 ::  {'max_depth': 38, 'learning_rate': 0.02297868986660416, 'n_estimators': 1450}\n",
      "loss: 0.8151650036559944\n",
      "----------------------------------------------------------------------------\n",
      "10 ::  {'max_depth': 24, 'learning_rate': 0.1143995088761935, 'n_estimators': 700}\n",
      "loss: 0.8113428796890176\n",
      "----------------------------------------------------------------------------\n",
      "11 ::  {'max_depth': 1, 'learning_rate': 0.07439794089052901, 'n_estimators': 100}\n",
      "loss: 0.7828308389125826\n",
      "----------------------------------------------------------------------------\n",
      "12 ::  {'max_depth': 30, 'learning_rate': 0.035159348091152454, 'n_estimators': 1550}\n",
      "loss: 0.8112885351141208\n",
      "----------------------------------------------------------------------------\n",
      "13 ::  {'max_depth': 36, 'learning_rate': 0.15618499578119666, 'n_estimators': 600}\n",
      "loss: 0.8097443585473111\n",
      "----------------------------------------------------------------------------\n",
      "14 ::  {'max_depth': 23, 'learning_rate': 0.03132444353580099, 'n_estimators': 200}\n",
      "loss: 0.8159807914551467\n",
      "----------------------------------------------------------------------------\n",
      "15 ::  {'max_depth': 45, 'learning_rate': 0.014103205587458678, 'n_estimators': 500}\n",
      "loss: 0.8167334709618028\n",
      "----------------------------------------------------------------------------\n",
      "16 ::  {'max_depth': 49, 'learning_rate': 0.05902822048243893, 'n_estimators': 1750}\n",
      "loss: 0.8092488751006399\n",
      "----------------------------------------------------------------------------\n",
      "17 ::  {'max_depth': 41, 'learning_rate': 0.2060787434112076, 'n_estimators': 1750}\n",
      "loss: 0.7933406796148689\n",
      "----------------------------------------------------------------------------\n",
      "18 ::  {'max_depth': 4, 'learning_rate': 0.09416399038559989, 'n_estimators': 700}\n",
      "loss: 0.811881562547986\n",
      "----------------------------------------------------------------------------\n",
      "19 ::  {'max_depth': 42, 'learning_rate': 0.04073845502232924, 'n_estimators': 550}\n",
      "loss: 0.8163200044809269\n",
      "----------------------------------------------------------------------------\n",
      "20 ::  {'max_depth': 35, 'learning_rate': 0.24423997545734005, 'n_estimators': 900}\n",
      "loss: 0.7979353919687006\n",
      "----------------------------------------------------------------------------\n",
      "21 ::  {'max_depth': 46, 'learning_rate': 0.01134582258830542, 'n_estimators': 400}\n",
      "loss: 0.8142027093604506\n",
      "----------------------------------------------------------------------------\n",
      "22 ::  {'max_depth': 45, 'learning_rate': 0.0522404109885613, 'n_estimators': 1200}\n",
      "loss: 0.8122319207363657\n",
      "----------------------------------------------------------------------------\n",
      "23 ::  {'max_depth': 15, 'learning_rate': 0.013737265561091288, 'n_estimators': 450}\n",
      "loss: 0.8141828004802517\n",
      "----------------------------------------------------------------------------\n",
      "24 ::  {'max_depth': 18, 'learning_rate': 0.0517198885053788, 'n_estimators': 50}\n",
      "loss: 0.8056505117058501\n",
      "----------------------------------------------------------------------------\n",
      "25 ::  {'max_depth': 45, 'learning_rate': 0.09997306445580283, 'n_estimators': 500}\n",
      "loss: 0.8144821957456341\n",
      "----------------------------------------------------------------------------\n",
      "26 ::  {'max_depth': 50, 'learning_rate': 0.06464416538146511, 'n_estimators': 1100}\n",
      "loss: 0.8105203285860656\n",
      "----------------------------------------------------------------------------\n",
      "27 ::  {'max_depth': 40, 'learning_rate': 0.04242080635169916, 'n_estimators': 2000}\n",
      "loss: 0.8105436191181642\n",
      "----------------------------------------------------------------------------\n",
      "28 ::  {'max_depth': 33, 'learning_rate': 0.011210174191240443, 'n_estimators': 850}\n",
      "loss: 0.8163476768718253\n",
      "----------------------------------------------------------------------------\n",
      "29 ::  {'max_depth': 34, 'learning_rate': 0.13395285567987777, 'n_estimators': 1250}\n",
      "loss: 0.8023417796519433\n",
      "----------------------------------------------------------------------------\n",
      "30 ::  {'max_depth': 32, 'learning_rate': 0.016152164763575404, 'n_estimators': 850}\n",
      "loss: 0.8165582918676131\n",
      "----------------------------------------------------------------------------\n",
      "31 ::  {'max_depth': 26, 'learning_rate': 0.08579642213939483, 'n_estimators': 300}\n",
      "loss: 0.8126929684883386\n",
      "----------------------------------------------------------------------------\n",
      "32 ::  {'max_depth': 27, 'learning_rate': 0.17873605576563106, 'n_estimators': 950}\n",
      "loss: 0.8028139725665155\n",
      "----------------------------------------------------------------------------\n",
      "33 ::  {'max_depth': 19, 'learning_rate': 0.13667154057884565, 'n_estimators': 800}\n",
      "loss: 0.8071538703053622\n",
      "----------------------------------------------------------------------------\n",
      "34 ::  {'max_depth': 29, 'learning_rate': 0.23796546372706978, 'n_estimators': 1200}\n",
      "loss: 0.7984730746207692\n",
      "----------------------------------------------------------------------------\n",
      "35 ::  {'max_depth': 21, 'learning_rate': 0.0709030859670918, 'n_estimators': 750}\n",
      "loss: 0.8130709990676166\n",
      "----------------------------------------------------------------------------\n",
      "36 ::  {'max_depth': 11, 'learning_rate': 0.11102461315370113, 'n_estimators': 1000}\n",
      "loss: 0.807037417644869\n",
      "----------------------------------------------------------------------------\n",
      "37 ::  {'max_depth': 32, 'learning_rate': 0.01536418782254377, 'n_estimators': 300}\n",
      "loss: 0.8153843823693816\n",
      "----------------------------------------------------------------------------\n",
      "38 ::  {'max_depth': 38, 'learning_rate': 0.02255696731716368, 'n_estimators': 1100}\n",
      "loss: 0.8171270285624797\n",
      "----------------------------------------------------------------------------\n",
      "39 ::  {'max_depth': 47, 'learning_rate': 0.16776052719867945, 'n_estimators': 1300}\n",
      "loss: 0.7989064499818439\n",
      "----------------------------------------------------------------------------\n",
      "40 ::  {'max_depth': 37, 'learning_rate': 0.12448305470927128, 'n_estimators': 1100}\n",
      "loss: 0.80702189062347\n",
      "----------------------------------------------------------------------------\n",
      "41 ::  {'max_depth': 39, 'learning_rate': 0.14544589945774059, 'n_estimators': 1600}\n",
      "loss: 0.7988399600374477\n",
      "----------------------------------------------------------------------------\n",
      "42 ::  {'max_depth': 43, 'learning_rate': 0.08501993874730894, 'n_estimators': 1350}\n",
      "loss: 0.8099073922720015\n",
      "----------------------------------------------------------------------------\n",
      "43 ::  {'max_depth': 49, 'learning_rate': 0.024692909720606185, 'n_estimators': 650}\n",
      "loss: 0.8166592175067071\n",
      "----------------------------------------------------------------------------\n",
      "44 ::  {'max_depth': 43, 'learning_rate': 0.04681062561492298, 'n_estimators': 1850}\n",
      "loss: 0.8103208587528774\n",
      "----------------------------------------------------------------------------\n",
      "45 ::  {'max_depth': 29, 'learning_rate': 0.20886811270976668, 'n_estimators': 150}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8150164967458031\n",
      "----------------------------------------------------------------------------\n",
      "46 ::  {'max_depth': 38, 'learning_rate': 0.06324435324394725, 'n_estimators': 1450}\n",
      "loss: 0.8101689701907862\n",
      "----------------------------------------------------------------------------\n",
      "47 ::  {'max_depth': 48, 'learning_rate': 0.09969200841130206, 'n_estimators': 1100}\n",
      "loss: 0.8079885667778135\n",
      "----------------------------------------------------------------------------\n",
      "48 ::  {'max_depth': 44, 'learning_rate': 0.03168287148542446, 'n_estimators': 550}\n",
      "loss: 0.8165971094211107\n",
      "----------------------------------------------------------------------------\n",
      "49 ::  {'max_depth': 36, 'learning_rate': 0.2287410686488734, 'n_estimators': 250}\n",
      "loss: 0.8116432751613001\n",
      "----------------------------------------------------------------------------\n",
      "50 ::  {'max_depth': 27, 'learning_rate': 0.0731709618605772, 'n_estimators': 650}\n",
      "loss: 0.8122285390844659\n",
      "----------------------------------------------------------------------------\n",
      "51 ::  {'max_depth': 0, 'learning_rate': 0.023641150263757578, 'n_estimators': 400}\n",
      "loss: 0.8163709674039239\n",
      "----------------------------------------------------------------------------\n",
      "52 ::  {'max_depth': 23, 'learning_rate': 0.039004120138702615, 'n_estimators': 950}\n",
      "loss: 0.8129147286467258\n",
      "----------------------------------------------------------------------------\n",
      "53 ::  {'max_depth': 15, 'learning_rate': 0.05358621867116471, 'n_estimators': 1500}\n",
      "loss: 0.8102587506672808\n",
      "----------------------------------------------------------------------------\n",
      "54 ::  {'max_depth': 40, 'learning_rate': 0.1955712081877795, 'n_estimators': 50}\n",
      "loss: 0.8142104728711501\n",
      "----------------------------------------------------------------------------\n",
      "55 ::  {'max_depth': 47, 'learning_rate': 0.11756335432841067, 'n_estimators': 1750}\n",
      "loss: 0.8004472448967539\n",
      "----------------------------------------------------------------------------\n",
      "56 ::  {'max_depth': 35, 'learning_rate': 0.08214906882340006, 'n_estimators': 2000}\n",
      "loss: 0.8045687641291133\n",
      "----------------------------------------------------------------------------\n",
      "57 ::  {'max_depth': 30, 'learning_rate': 0.17147820476609152, 'n_estimators': 1200}\n",
      "loss: 0.8027208104381212\n",
      "----------------------------------------------------------------------------\n",
      "58 ::  {'max_depth': 42, 'learning_rate': 0.10739230222458757, 'n_estimators': 1050}\n",
      "loss: 0.808648084156075\n",
      "----------------------------------------------------------------------------\n",
      "59 ::  {'max_depth': 6, 'learning_rate': 0.09057856620220274, 'n_estimators': 750}\n",
      "loss: 0.8115025317618082\n",
      "----------------------------------------------------------------------------\n",
      "60 ::  {'max_depth': 45, 'learning_rate': 0.05973143244552553, 'n_estimators': 450}\n",
      "loss: 0.8165184741072153\n",
      "----------------------------------------------------------------------------\n",
      "61 ::  {'max_depth': 38, 'learning_rate': 0.02011788676458604, 'n_estimators': 550}\n",
      "loss: 0.8164529843697192\n",
      "----------------------------------------------------------------------------\n",
      "62 ::  {'max_depth': 41, 'learning_rate': 0.0372501657637722, 'n_estimators': 1350}\n",
      "loss: 0.8125012621658498\n",
      "----------------------------------------------------------------------------\n",
      "63 ::  {'max_depth': 33, 'learning_rate': 0.010053845325440278, 'n_estimators': 900}\n",
      "loss: 0.8167921973954994\n",
      "----------------------------------------------------------------------------\n",
      "64 ::  {'max_depth': 20, 'learning_rate': 0.02981542774885302, 'n_estimators': 1700}\n",
      "loss: 0.812107704565173\n",
      "----------------------------------------------------------------------------\n",
      "65 ::  {'max_depth': 25, 'learning_rate': 0.14661203177904916, 'n_estimators': 1850}\n",
      "loss: 0.7974986349557261\n",
      "----------------------------------------------------------------------------\n",
      "66 ::  {'max_depth': 34, 'learning_rate': 0.04620366606564376, 'n_estimators': 900}\n",
      "loss: 0.8118228361142895\n",
      "----------------------------------------------------------------------------\n",
      "67 ::  {'max_depth': 50, 'learning_rate': 0.010061057695974525, 'n_estimators': 750}\n",
      "loss: 0.8166669810174066\n",
      "----------------------------------------------------------------------------\n",
      "68 ::  {'max_depth': 32, 'learning_rate': 0.0698563819500084, 'n_estimators': 1150}\n",
      "loss: 0.8104028757186725\n",
      "----------------------------------------------------------------------------\n",
      "69 ::  {'max_depth': 28, 'learning_rate': 0.02463666410971242, 'n_estimators': 1000}\n",
      "loss: 0.8157269770470615\n",
      "----------------------------------------------------------------------------\n",
      "70 ::  {'max_depth': 36, 'learning_rate': 0.05269741603337377, 'n_estimators': 600}\n",
      "loss: 0.8154731626389764\n",
      "----------------------------------------------------------------------------\n",
      "71 ::  {'max_depth': 31, 'learning_rate': 0.01804628980875886, 'n_estimators': 350}\n",
      "loss: 0.8154974533779749\n",
      "----------------------------------------------------------------------------\n",
      "72 ::  {'max_depth': 23, 'learning_rate': 0.07681511117428935, 'n_estimators': 800}\n",
      "loss: 0.8107896700155498\n",
      "----------------------------------------------------------------------------\n",
      "73 ::  {'max_depth': 39, 'learning_rate': 0.03535649253429536, 'n_estimators': 900}\n",
      "loss: 0.8138314420849722\n",
      "----------------------------------------------------------------------------\n",
      "74 ::  {'max_depth': 16, 'learning_rate': 0.02795920157447964, 'n_estimators': 700}\n",
      "loss: 0.8153800005105818\n",
      "----------------------------------------------------------------------------\n",
      "75 ::  {'max_depth': 34, 'learning_rate': 0.04204408766707286, 'n_estimators': 1250}\n",
      "loss: 0.8128171846595313\n",
      "----------------------------------------------------------------------------\n",
      "76 ::  {'max_depth': 43, 'learning_rate': 0.011261418267824331, 'n_estimators': 1050}\n",
      "loss: 0.8167101804297041\n",
      "----------------------------------------------------------------------------\n",
      "77 ::  {'max_depth': 11, 'learning_rate': 0.06662232766113568, 'n_estimators': 500}\n",
      "loss: 0.8134645566682936\n",
      "----------------------------------------------------------------------------\n",
      "78 ::  {'max_depth': 46, 'learning_rate': 0.09672365508259224, 'n_estimators': 150}\n",
      "loss: 0.8161404435279375\n",
      "----------------------------------------------------------------------------\n",
      "79 ::  {'max_depth': 37, 'learning_rate': 0.05654343340754928, 'n_estimators': 1150}\n",
      "loss: 0.8125910426423446\n",
      "----------------------------------------------------------------------------\n",
      "80 ::  {'max_depth': 25, 'learning_rate': 0.10581926903054552, 'n_estimators': 950}\n",
      "loss: 0.8099428281735994\n",
      "----------------------------------------------------------------------------\n",
      "81 ::  {'max_depth': 40, 'learning_rate': 0.047499766187378605, 'n_estimators': 1400}\n",
      "loss: 0.8120445962726766\n",
      "----------------------------------------------------------------------------\n",
      "82 ::  {'max_depth': 49, 'learning_rate': 0.24802856780665516, 'n_estimators': 800}\n",
      "loss: 0.802516958746133\n",
      "----------------------------------------------------------------------------\n",
      "83 ::  {'max_depth': 29, 'learning_rate': 0.010020039070962395, 'n_estimators': 600}\n",
      "loss: 0.8160938624637402\n",
      "----------------------------------------------------------------------------\n",
      "84 ::  {'max_depth': 33, 'learning_rate': 0.12042201096402844, 'n_estimators': 1550}\n",
      "loss: 0.8035312161715737\n",
      "----------------------------------------------------------------------------\n",
      "85 ::  {'max_depth': 44, 'learning_rate': 0.03266428375735684, 'n_estimators': 1300}\n",
      "loss: 0.8132617051832055\n",
      "----------------------------------------------------------------------------\n",
      "86 ::  {'max_depth': 31, 'learning_rate': 0.09018237217459561, 'n_estimators': 850}\n",
      "loss: 0.8112608627232222\n",
      "----------------------------------------------------------------------------\n",
      "87 ::  {'max_depth': 47, 'learning_rate': 0.12994534832030852, 'n_estimators': 300}\n",
      "loss: 0.8140808746342577\n",
      "----------------------------------------------------------------------------\n",
      "88 ::  {'max_depth': 21, 'learning_rate': 0.017865304144721834, 'n_estimators': 650}\n",
      "loss: 0.8168154879275981\n",
      "----------------------------------------------------------------------------\n",
      "89 ::  {'max_depth': 17, 'learning_rate': 0.1907840516294404, 'n_estimators': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8017176981752796\n",
      "----------------------------------------------------------------------------\n",
      "90 ::  {'max_depth': 9, 'learning_rate': 0.020537879875035178, 'n_estimators': 700}\n",
      "loss: 0.8148025000981156\n",
      "----------------------------------------------------------------------------\n",
      "91 ::  {'max_depth': 21, 'learning_rate': 0.0794083840173824, 'n_estimators': 1150}\n",
      "loss: 0.8111710822467276\n",
      "----------------------------------------------------------------------------\n",
      "92 ::  {'max_depth': 14, 'learning_rate': 0.16035346161816688, 'n_estimators': 850}\n",
      "loss: 0.8093099829793362\n",
      "----------------------------------------------------------------------------\n",
      "93 ::  {'max_depth': 22, 'learning_rate': 0.22344548306062412, 'n_estimators': 1250}\n",
      "loss: 0.7981304799430893\n",
      "----------------------------------------------------------------------------\n",
      "94 ::  {'max_depth': 19, 'learning_rate': 0.04454388781866422, 'n_estimators': 1450}\n",
      "loss: 0.814076492775458\n",
      "----------------------------------------------------------------------------\n",
      "95 ::  {'max_depth': 13, 'learning_rate': 0.016449172289156894, 'n_estimators': 650}\n",
      "loss: 0.8159298285321497\n",
      "----------------------------------------------------------------------------\n",
      "96 ::  {'max_depth': 26, 'learning_rate': 0.06373639097514111, 'n_estimators': 400}\n",
      "loss: 0.8150563145062006\n",
      "----------------------------------------------------------------------------\n",
      "97 ::  {'max_depth': 24, 'learning_rate': 0.058588891692586215, 'n_estimators': 1100}\n",
      "loss: 0.8129690732216226\n",
      "----------------------------------------------------------------------------\n",
      "98 ::  {'max_depth': 2, 'learning_rate': 0.027168332185858915, 'n_estimators': 1650}\n",
      "loss: 0.812789512268633\n",
      "----------------------------------------------------------------------------\n",
      "99 ::  {'max_depth': 27, 'learning_rate': 0.050285483270989514, 'n_estimators': 450}\n",
      "loss: 0.81660825458371\n",
      "----------------------------------------------------------------------------\n",
      "100 ::  {'max_depth': 18, 'learning_rate': 0.03328607626365643, 'n_estimators': 1050}\n",
      "loss: 0.8119126165907843\n",
      "{'learning_rate': 0.02255696731716368, 'max_depth': 38.0, 'n_estimators': 1100.0}\n"
     ]
    }
   ],
   "source": [
    "space = {'max_depth': hp.quniform('max_depth', -1, 50, 1),\n",
    "         'n_estimators': hp.quniform('n_estimators', 50, 2000, 50),\n",
    "         'learning_rate': hp.uniform('learning_rate', 0.01, 0.25),\n",
    "        }\n",
    "\n",
    "header = [\"iter\", \"acc\", \"f1-score\", \"auc\", \"recall\", \"cm\", \"params\"]\n",
    "write(folder_name, header)\n",
    "\n",
    "ITER = 0\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective_function,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            rstate= np.random.default_rng(seed),\n",
    "            max_evals=100,\n",
    "            verbose=False,\n",
    "            trials=trials)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246ce4b",
   "metadata": {},
   "source": [
    "## Save hyperparameters dictionary to numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bddd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data types are correct\n",
    "best = {\n",
    "        'max_depth': int(best['max_depth']), \n",
    "        'learning_rate': best['learning_rate'],\n",
    "        'n_estimators': int(best['n_estimators']),\n",
    "        }\n",
    "np.save(folder_name + '/LGBM_hyperparameters.npy', best) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c406d3fe",
   "metadata": {},
   "source": [
    "## Single Run of Best Non-Private LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba39a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics\n",
      "acc: 0.818102508178844\n",
      "f1: 0.8278282411230389\n",
      "auc: 0.8171270285624797\n",
      "recall: 0.8445661331086773\n",
      "\n",
      "Fairness Metrics\n",
      "SP_a_1: 0.6636895095810328\n",
      "SP_a_0: 0.28320053120849936\n",
      "DI: 0.42670635458329803\n",
      "SPD: 0.3804889783725334\n",
      "EO_a_1: 0.8929614873837981\n",
      "EO_a_0: 0.659206510681587\n",
      "EOD: 0.23375497670221113\n",
      "OA_a_1: 0.8168236440402729\n",
      "OA_a_0: 0.8207171314741036\n",
      "OAD: -0.003893487433830778\n"
     ]
    }
   ],
   "source": [
    "params = np.load(folder_name + '/LGBM_hyperparameters.npy', allow_pickle='TRUE').item()\n",
    "\n",
    "model = LGBMClassifier(random_state=seed, n_jobs=-1, objective=\"binary\")\n",
    "model.set_params(**params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# performance metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print('Performance Metrics')\n",
    "print(\"acc:\", acc)\n",
    "print(\"f1:\", f1)\n",
    "print(\"auc:\", auc)\n",
    "print(\"recall:\", recall)\n",
    "\n",
    "# prepare dataset for fairness metrics\n",
    "df_fm = pd.concat([X_test, y_test], axis=1)\n",
    "df_fm['y_pred'] = y_pred\n",
    "\n",
    "print('\\nFairness Metrics')\n",
    "\n",
    "fair_met = fairness_metrics(df_fm, protected_attribute, target)\n",
    "\n",
    "for key in fair_met.keys():\n",
    "    print(key+\":\", fair_met[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80bbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
